{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Regressão Linear - Previsão de IMC\n",
    "\n",
    " Legendas:\n",
    "   * <code style=\"color:green\">Teoria/Instruções</code>\n",
    "   * <code style=\"color:purple\">Comentários</code>\n",
    "   * <code style=\"color:red\">Dúvidas a serem esclarecidas</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importando a biblioteca de manipulação de dados\n",
    "import statsmodels.api as sm # biblioteca para a regressão logística\n",
    "import numpy as np # biblioteca para calculo\n",
    "from matplotlib import pyplot as plt # importando a biblioteca de visualização de dados \n",
    "import seaborn as sns# importando a biblioteca de visualização de dados \n",
    "from tabulate import tabulate # biblioteca para estilizar tabelas\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # funções de erro\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor # funções para calcular o vif\n",
    "import scipy.stats as stats # biblioteca para modelagem\n",
    "import pylab # biblioteca para o qqplot\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan # função para o teste de breusch-pagan\n",
    "from scipy.stats import shapiro # teste de normalidade\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Funções para seleção de variáveis utilizando métodos backward, forward e stepwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza uma seleção forward stepwise com base no p-valor das variáveis independentes.\n",
    "# A cada passo, adiciona a variável independente com o menor p-valor ao modelo, desde que o p-valor \n",
    "# seja menor que o nível de significância especificado.\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# - signif: Nível de significância para a inclusão das variáveis (por exemplo, 0.05).\n",
    "# Retorna: DataFrame contendo as variáveis selecionadas e seus respectivos p-valores.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def selecionar_pvalor_forward(var_dependente, var_independente, base, signif):\n",
    "\n",
    "    preditoras = []\n",
    "    pvalor_preditoras = []\n",
    "    Y = base[var_dependente]\n",
    "    while True and var_independente != [] :\n",
    "        lista_pvalor = []\n",
    "        lista_variavel = []\n",
    "        for var in var_independente:\n",
    "            X = sm.add_constant(base[ [var] +  preditoras ])\n",
    "            \n",
    "            modelo = sm.OLS(Y,X).fit()\n",
    "            \n",
    "            if( preditoras == []):\n",
    "    \n",
    "                pvalor = modelo.pvalues[1]\n",
    "                variavel = modelo.pvalues.index[1]\n",
    "            \n",
    "            else:\n",
    "                pvalor = modelo.pvalues.drop(preditoras)[1]\n",
    "                variavel = modelo.pvalues.drop(preditoras).index[1]\n",
    "                \n",
    "            lista_pvalor.append(pvalor)\n",
    "            lista_variavel.append(variavel)          \n",
    "        \n",
    "        if( lista_pvalor[ np.argmin(lista_pvalor) ] < signif ):\n",
    "            preditoras.append( lista_variavel[np.argmin(lista_pvalor)] )\n",
    "            pvalor_preditoras.append(lista_pvalor[ np.argmin(lista_pvalor) ])\n",
    "            var_independente.remove( lista_variavel[ np.argmin(lista_pvalor)] )\n",
    "        else:\n",
    "            break\n",
    "    info_final = pd.DataFrame({ 'var': preditoras, 'pvalor': pvalor_preditoras})\n",
    "    return info_final\n",
    "\n",
    "# Exemplo de uso\n",
    "# colunas_pvalor = selecionar_pvalor_forward(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat, signif=0.05)\n",
    "# colunas_pvalor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza uma seleção forward stepwise com base no critério de informação de Akaike (AIC).\n",
    "# A cada passo, adiciona a variável independente que minimiza o AIC ao modelo.\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# Retorna: DataFrame contendo as combinações de variáveis selecionadas e seus respectivos AICs, \n",
    "# ordenados do menor para o maior AIC.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def selecionar_aic_forward(var_dependente, var_independente, base):\n",
    "    \n",
    "    preditoras = []\n",
    "    aic_preditoras = []\n",
    "    Y = base[var_dependente]\n",
    "    lista_final = []\n",
    "    aic_melhor = float('inf')\n",
    "    \n",
    "    while True and var_independente != []:\n",
    "        lista_aic = []\n",
    "        lista_variavel = []\n",
    "        lista_modelos =[]\n",
    "        if(var_independente == []):\n",
    "            break\n",
    "        for var in var_independente:\n",
    "            X = sm.add_constant(base[ [var] +  preditoras ])\n",
    "            aic = sm.OLS(Y,X).fit().aic\n",
    "            variavel = var\n",
    "                \n",
    "            lista_aic.append(aic)\n",
    "            \n",
    "            lista_variavel.append(var)\n",
    "            \n",
    "            lista_modelos.append( [var] +  preditoras )\n",
    "            \n",
    "        if( lista_aic[ np.argmin(lista_aic) ] < aic_melhor ):\n",
    "            \n",
    "            lista_final.append(lista_modelos[ np.argmin(lista_aic)]  )\n",
    "            \n",
    "            preditoras.append( lista_variavel[np.argmin(lista_aic)] )\n",
    "            \n",
    "            aic_preditoras.append(lista_aic[ np.argmin(lista_aic) ])\n",
    "            \n",
    "            var_independente.remove( lista_variavel[ np.argmin(lista_aic)] )\n",
    "            \n",
    "            aic_melhor = lista_aic[ np.argmin(lista_aic) ] \n",
    "            \n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    info_final = pd.DataFrame({ 'var': lista_final, 'aic': aic_preditoras}).sort_values(by = 'aic')\n",
    "    return info_final\n",
    "\n",
    "# Exemplo de uso\n",
    "# colunas_aic = selecionar_aic_forward(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat)\n",
    "# colunas_aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza uma seleção forward stepwise com base no critério de informação bayesiano (BIC).\n",
    "# A cada passo, adiciona a variável independente que minimiza o BIC ao modelo.\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# Retorna: DataFrame contendo as combinações de variáveis selecionadas e seus respectivos BICs, \n",
    "# ordenados do menor para o maior BIC.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def selecionar_bic_forward(var_dependente, var_independente, base):\n",
    "    \n",
    "    preditoras = []\n",
    "    bic_preditoras = []\n",
    "    Y = base[var_dependente]\n",
    "    lista_final = []\n",
    "    bic_melhor = float('inf')\n",
    "    \n",
    "    while True and var_independente != []:\n",
    "        lista_bic = []\n",
    "        lista_variavel = []\n",
    "        lista_modelos =[]\n",
    "        if(var_independente == []):\n",
    "            break\n",
    "        for var in var_independente:\n",
    "            X = sm.add_constant(base[ [var] +  preditoras ])\n",
    "            bic = sm.OLS(Y,X).fit().bic\n",
    "            variavel = var\n",
    "                \n",
    "            lista_bic.append(bic)\n",
    "            \n",
    "            lista_variavel.append(var)\n",
    "            \n",
    "            lista_modelos.append( [var] +  preditoras )\n",
    "            \n",
    "        if( lista_bic[ np.argmin(lista_bic) ] < bic_melhor ):\n",
    "            \n",
    "            lista_final.append(lista_modelos[ np.argmin(lista_bic)]  )\n",
    "            \n",
    "            preditoras.append( lista_variavel[np.argmin(lista_bic)] )\n",
    "            \n",
    "            bic_preditoras.append(lista_bic[ np.argmin(lista_bic) ])\n",
    "            \n",
    "            var_independente.remove( lista_variavel[ np.argmin(lista_bic)] )\n",
    "            \n",
    "            aic_melhor = lista_bic[ np.argmin(lista_bic) ] \n",
    "            \n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    info_final = pd.DataFrame({ 'var': lista_final, 'bic': bic_preditoras}).sort_values(by = 'bic')\n",
    "    return info_final\n",
    "\n",
    "# Exemplo de uso\n",
    "# colunas_bic = selecionar_bic_forward(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat)\n",
    "# colunas_bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza uma seleção backward stepwise com base no p-valor das variáveis independentes.\n",
    "# A cada passo, remove a variável independente com o maior p-valor do modelo, \n",
    "# desde que seja maior que o nível de significância especificado.\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# - signif: Nível de significância para a remoção das variáveis (por exemplo, 0.05).\n",
    "# Retorna: DataFrame contendo as variáveis restantes após a seleção backward.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def selecionar_pvalor_backward(var_dependente, var_independente, base, signif):\n",
    "    Y = base[var_dependente]\n",
    "    \n",
    "    while True and var_independente != []:\n",
    "        \n",
    "        X_geral = sm.add_constant(base[var_independente])\n",
    "        \n",
    "        modelo = sm.OLS(Y,X_geral).fit()\n",
    "        \n",
    "        pvalor_geral = modelo.pvalues\n",
    "        \n",
    "        variavel_geral = modelo.pvalues.index\n",
    "        \n",
    "        if(pvalor_geral[ np.argmax(pvalor_geral) ] > signif ):\n",
    "            var_independente.remove( variavel_geral[ np.argmax(pvalor_geral) ] )\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    info_final = pd.DataFrame({ 'var': var_independente})\n",
    "    return info_final\n",
    "\n",
    "# Exemplo de uso\n",
    "# colunas_pvalor_back = selecionar_pvalor_backward(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat, signif=0.05)\n",
    "# colunas_pvalor_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza uma seleção backward stepwise com base no critério de informação de Akaike (AIC).\n",
    "# A cada passo, remove a variável que minimiza o AIC, desde que a remoção resulte em um AIC menor do que o modelo atual.\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# Retorna: DataFrame contendo as combinações de variáveis selecionadas e seus respectivos AICs, \n",
    "# ordenados do menor para o maior AIC.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def selecionar_aic_backward(var_dependente, var_independente, base):\n",
    "    Y = base[var_dependente]\n",
    "    \n",
    "    preditoras_finais = []\n",
    "    \n",
    "    aic_final = []\n",
    "    \n",
    "    while True and var_independente != []:\n",
    "        \n",
    "        lista_aic = []\n",
    "        lista_preditoras = []\n",
    "\n",
    "        X_geral = sm.add_constant(base[var_independente])\n",
    "        \n",
    "        aic_geral = sm.OLS(Y,X_geral).fit().aic\n",
    "    \n",
    "        aic_final.append(aic_geral)\n",
    "        \n",
    "        preditoras_finais.append(base[var_independente].columns.to_list())\n",
    "        \n",
    "        for var in var_independente:\n",
    "            \n",
    "            lista_variaveis = var_independente.copy()\n",
    "            lista_variaveis.remove(var)\n",
    "            \n",
    "            X = sm.add_constant(base[ lista_variaveis ])\n",
    "            aic = sm.OLS(Y,X).fit().aic    \n",
    "            \n",
    "            lista_aic.append(aic)\n",
    "            \n",
    "            lista_preditoras.append(var)\n",
    "            \n",
    "        if(lista_aic[ np.argmin(lista_aic) ] < aic_geral ):\n",
    "            var_independente.remove( lista_preditoras[ np.argmin(lista_aic) ] )\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    info_final = pd.DataFrame({ 'var': preditoras_finais, 'aic':aic_final }).sort_values(by = 'aic')\n",
    "    return info_final\n",
    "\n",
    "# Exemplo de uso\n",
    "# colunas_aic_back = selecionar_aic_backward(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat)\n",
    "# colunas_aic_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza uma seleção backward stepwise com base no critério de informação bayesiano (BIC).\n",
    "# A cada passo, remove a variável que minimiza o BIC, desde que a remoção resulte em um BIC menor do que o modelo atual.\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# Retorna: DataFrame contendo as combinações de variáveis selecionadas e seus respectivos BICs, \n",
    "# ordenados do menor para o maior BIC.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def selecionar_bic_backward(var_dependente, var_independente, base):\n",
    "    Y = base[var_dependente]\n",
    "    \n",
    "    preditoras_finais = []\n",
    "    \n",
    "    bic_final = []\n",
    "    \n",
    "    while True and var_independente != []:\n",
    "        \n",
    "        lista_bic = []\n",
    "        lista_preditoras = []\n",
    "\n",
    "        X_geral = sm.add_constant(base[var_independente])\n",
    "        \n",
    "        bic_geral = sm.OLS(Y,X_geral).fit().bic\n",
    "    \n",
    "        bic_final.append(bic_geral)\n",
    "        \n",
    "        preditoras_finais.append(base[var_independente].columns.to_list())\n",
    "        \n",
    "        for var in var_independente:\n",
    "            \n",
    "            lista_variaveis = var_independente.copy()\n",
    "            lista_variaveis.remove(var)\n",
    "            \n",
    "            X = sm.add_constant(base[ lista_variaveis ])\n",
    "            bic = sm.OLS(Y,X).fit().bic    \n",
    "            \n",
    "            lista_bic.append(bic)\n",
    "            \n",
    "            lista_preditoras.append(var)\n",
    "            \n",
    "        if(lista_bic[ np.argmin(lista_bic) ] < bic_geral ):\n",
    "            var_independente.remove( lista_preditoras[ np.argmin(lista_bic) ] )\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    info_final = pd.DataFrame({ 'var': preditoras_finais, 'bic':bic_final }).sort_values(by = 'bic')\n",
    "    return info_final\n",
    "\n",
    "# Exemplo de uso\n",
    "# colunas_bic_back = selecionar_bic_backward(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat)\n",
    "# colunas_bic_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza a seleção stepwise de variáveis, usando os métodos forward e backward \n",
    "# com base em uma métrica específica (AIC, BIC ou p-valor).\n",
    "# O processo consiste em primeiro aplicar a seleção forward com a métrica escolhida e, \n",
    "# em seguida, a backward, ajustando o modelo até que a diferença entre as métricas seja menor \n",
    "# que um valor de tolerância (epsilon).\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# - metrica: A métrica a ser usada no processo de seleção (pode ser 'aic', 'bic', ou 'pvalor').\n",
    "# - signif: Nível de significância usado para a seleção por p-valor (padrão 0.05).\n",
    "# - epsilon: Diferença mínima aceitável entre as métricas forward e backward para parar o processo (padrão 0.0001).\n",
    "# Retorna: DataFrame contendo as variáveis selecionadas e suas respectivas métricas (AIC, BIC ou p-valor), \n",
    "# dependendo da métrica usada.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def stepwise( var_dependente , var_independente , base, metrica, signif = 0.05, epsilon = 0.0001):\n",
    "    \n",
    "    lista_var = var_independente\n",
    "    \n",
    "    metrica_forward = 0\n",
    "    \n",
    "    metrica_backward = 0\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        if(metrica == 'aic'):\n",
    "            resultado = selecionar_aic_forward(var_dependente = var_dependente, var_independente = var_independente, base = base)\n",
    "\n",
    "            if (len(resultado) == 1):\n",
    "                return resultado\n",
    "            \n",
    "            resultado_final = selecionar_aic_backward(var_dependente = var_dependente, var_independente = resultado['var'].to_list()[0], base = base)\n",
    "\n",
    "            if(len(resultado_final) == 1):\n",
    "                return resultado_final\n",
    "\n",
    "            metrica_forward = resultado['aic'].to_list()[0]\n",
    "\n",
    "            metrica_backward = resultado_final['aic'].to_list()[0]\n",
    "\n",
    "\n",
    "        elif(metrica == 'bic'):\n",
    "            resultado = selecionar_bic_forward(var_dependente = var_dependente, var_independente = var_independente, base = base)\n",
    "\n",
    "            if (len(resultado) == 1):\n",
    "                return resultado\n",
    "\n",
    "            resultado_final = selecionar_bic_backward(var_dependente = var_dependente, var_independente = resultado['var'].to_list()[0], base = base)\n",
    "\n",
    "            if(len(resultado_final) == 1):\n",
    "                return resultado_final\n",
    "\n",
    "            metrica_forward = resultado['bic'].to_list()[0]\n",
    "\n",
    "            metrica_backward = resultado_final['bic'].to_list()[0]\n",
    "\n",
    "        elif(metrica == 'pvalor'):\n",
    "            resultado = selecionar_pvalor_forward(var_dependente = var_dependente, var_independente = var_independente, base = base, signif = signif)\n",
    "\n",
    "            if (len(resultado) == 1):\n",
    "                return resultado\n",
    "\n",
    "            resultado_final = selecionar_pvalor_backward(var_dependente = var_dependente, var_independente = resultado['var'].to_list(), base = base, signif = signif)\n",
    "\n",
    "            if(len(resultado_final) == 1):\n",
    "                return resultado_final\n",
    "\n",
    "            return resultado_final\n",
    "\n",
    "        if( abs(metrica_forward - metrica_backward) < epsilon ):\n",
    "            break\n",
    "        else:\n",
    "            var_independente = set(resultado_final['var'].to_list() + lista_var)\n",
    "\n",
    "# Exemplo de uso\n",
    "# colunas_stepwise = stepwise(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat, metrica='aic', signif=0.05)\n",
    "# colunas_stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função realiza a seleção de variáveis usando os métodos forward, backward ou stepwise, com base em uma métrica escolhida (AIC, BIC ou p-valor).\n",
    "# O usuário pode escolher o método de seleção (forward, backward ou both) e a métrica desejada para o critério de inclusão ou exclusão de variáveis.\n",
    "# Parâmetros:\n",
    "# - var_dependente: Nome da variável dependente.\n",
    "# - var_independente: Lista de variáveis independentes a serem avaliadas.\n",
    "# - base: Conjunto de dados contendo as variáveis dependentes e independentes.\n",
    "# - metodo: Método de seleção ('forward', 'backward' ou 'both').\n",
    "# - metrica: A métrica a ser utilizada para a seleção ('aic', 'bic' ou 'pvalor').\n",
    "# - signif: Nível de significância usado para a seleção por p-valor (padrão 0.05).\n",
    "# Retorna: Resultado da seleção de variáveis com base no método e métrica escolhidos.\n",
    "# criada por Mateus Rocha - time ASN.Rocks\n",
    "\n",
    "def step( var_dependente , var_independente , base, metodo, metrica, signif = 0.05):\n",
    "    \n",
    "    if( metodo == 'forward' and metrica == 'aic' ):\n",
    "        resultado = selecionar_aic_forward(var_dependente = var_dependente, var_independente = var_independente, base = base)\n",
    "    elif(metodo == 'forward' and metrica == 'bic' ):\n",
    "        resultado = selecionar_bic_forward(var_dependente = var_dependente, var_independente = var_independente, base = base)\n",
    "    elif(metodo == 'forward' and metrica == 'pvalor' ):\n",
    "        resultado = selecionar_pvalor_forward(var_dependente = var_dependente, var_independente = var_independente, base = base, signif = signif)\n",
    "    elif( metodo == 'backward' and metrica == 'aic' ):\n",
    "        resultado = selecionar_aic_backward(var_dependente = var_dependente, var_independente = var_independente, base = base)\n",
    "    elif(metodo == 'backward'and metrica == 'bic' ):\n",
    "        resultado = selecionar_bic_backward(var_dependente = var_dependente, var_independente = var_independente, base = base)\n",
    "    elif(metodo == 'backward' and metrica == 'pvalor' ):\n",
    "        resultado = selecionar_pvalor_backward(var_dependente = var_dependente, var_independente = var_independente, base = base, signif = signif)\n",
    "    elif(metodo == 'both'):\n",
    "        resultado = stepwise( var_dependente = var_dependente , var_independente = var_independente , base = base, metrica = metrica, signif = signif)\n",
    "        \n",
    "    # Ajustar a exibição do pandas para não truncar as colunas e linhas longas\n",
    "    pd.set_option('display.max_colwidth', None)  # Não cortar as colunas\n",
    "    pd.set_option('display.max_rows', None)  # Mostrar todas as linhas\n",
    "    \n",
    "    return resultado\n",
    "    \n",
    "# Exemplo de uso\n",
    "# colunas_step = step(var_dependente='bodyfat', var_independente=X.columns.to_list(), base=Bodyfat, metodo='both', metrica='aic', signif=0.05)\n",
    "# colunas_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1. Definição do problema de negócio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Contexto\n",
    "\n",
    "Para termos uma medida precisa da gordura corporal do nosso corpo, o processo é custoso, inconveniente e cansativo. Sendo assim, é desejável que existam métodos fáceis de estimar a gordura corporal que não sejam inconvenientes, nem tão custosos.\n",
    "Com os dados do arquivo Bodyfat.csv, criaremos um modelo para identificar a melhor forma de prever o valor do IMC utilizando variáveis independentes, validaremos o modelo e verificaremos se não tem multicolinearidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>2. Entendimento e aquisição de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Importando arquivo de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Bodyfat.csv\")\n",
    "df = df.select_dtypes(include=['number']) # Filtrar apenas colunas numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Dicionário de dados\n",
    "\n",
    "| Variável  | Descrição | Unidade de Medida | Tipo | Comentário |\n",
    "|-----------|-----------|------------------|------|------------|\n",
    "| Density   | Densidade corporal, usada para calcular a gordura corporal | - | Quantitativa contínua | Não será utilizada na análise |\n",
    "| bodyfat   | Percentual de gordura corporal, a variável alvo | % | Quantitativa contínua | Variável dependente (target). Validar outlier com a área de negócio |\n",
    "| Age       | Idade do indivíduo | Anos | Quantitativa discreta | - |\n",
    "| Weight    | Peso do indivíduo | Libras | Quantitativa contínua | - |\n",
    "| Height    | Altura do indivíduo | Polegadas | Quantitativa contínua | Tratar outlier de altura |\n",
    "| Neck      | Circunferência do pescoço | Polegadas | Quantitativa contínua | - |\n",
    "| Chest     | Circunferência do peito | Polegadas | Quantitativa contínua | - |\n",
    "| Abdomen   | Circunferência abdominal | Polegadas | Quantitativa contínua | - |\n",
    "| Hip       | Circunferência do quadril | Polegadas | Quantitativa contínua | - |\n",
    "| Thigh     | Circunferência da coxa | Polegadas | Quantitativa contínua | - |\n",
    "| Knee      | Circunferência do joelho | Polegadas | Quantitativa contínua | - |\n",
    "| Ankle     | Circunferência do tornozelo | Polegadas | Quantitativa contínua | - |\n",
    "| Biceps    | Circunferência do bíceps em repouso | Polegadas | Quantitativa contínua | - |\n",
    "| Forearm   | Circunferência do antebraço | Polegadas | Quantitativa contínua | - |\n",
    "| Wrist     | Circunferência do punho | Polegadas | Quantitativa contínua | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Conhecendo minhas variáveis\n",
    "\n",
    "#### <code style=\"color:green\">Análise Univariada</code>\n",
    "\n",
    "Antes de realizar qualquer modelagem, devemos sempre analisar nossas variáveis, em especial a variável dependente.\n",
    "\n",
    "Podemos fazer uso de ferramentas como:\n",
    "\n",
    "- Análises Descritivas;\n",
    "- Gráficos boxplot;\n",
    "- Gráficos histograma;\n",
    "- Gráficos de dispersão.\n",
    "\n",
    "A ideia é analisar do que se tratam os dados e se possuem algo estranho.\n",
    "\n",
    "- Observar se a mediana e média estão próximas;\n",
    "- Verificar se existem valores estranhos de mínimo e máximo, por exemplo, valores negativos no mínimo e valores = 0 no máx;\n",
    "- Observar o movimento dos dados analisando os quartis;\n",
    "- Criar coluna no dicionário de dados para anotar observações sobre cada variável para alinhar com a área de negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas e primeiras linhas da base de dados\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando unidade de medida das variáveis para facilitar interpretação\n",
    "\n",
    "# Transformando a variável weight de libras para quilos\n",
    "df['Weight'] = df['Weight'] * 0.453592\n",
    "\n",
    "# Transformando as variáveis em polegadas para centímetros\n",
    "df['Height'] = df['Height'] * 2.54\n",
    "df['Neck'] = df['Neck'] * 2.54\n",
    "df['Chest'] = df['Chest'] * 2.54\n",
    "df['Abdomen'] = df['Abdomen'] * 2.54\n",
    "df['Hip'] = df['Hip'] * 2.54\n",
    "df['Thigh'] = df['Thigh'] * 2.54\n",
    "df['Knee'] = df['Knee'] * 2.54\n",
    "df['Ankle'] = df['Ankle'] * 2.54\n",
    "df['Biceps'] = df['Biceps'] * 2.54\n",
    "df['Forearm'] = df['Forearm'] * 2.54\n",
    "df['Wrist'] = df['Wrist'] * 2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores faltantes e tipos de dados de cada campo\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando principais valores estatísticos das variáveis em questão. Atenção especial à variável dependente (y)\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando boxplot, histograma e violino de cada variável\n",
    "def plot_histogram_boxplot(df):\n",
    "    \n",
    "    # Gera histogramas e boxplots para todas as colunas numéricas de um DataFrame.\n",
    "\n",
    "    num_cols = df.select_dtypes(include=['number']).columns  # Filtra apenas colunas numéricas\n",
    "    \n",
    "    for coluna in num_cols:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Criar subplots lado a lado\n",
    "\n",
    "        # Histograma com densidade\n",
    "        sns.histplot(df[coluna], kde=True, bins=30, color=\"#39568C\", ax=axes[0]) # kde=True adiciona a curva de densidade\n",
    "        axes[0].set_title(f\"Histograma de {coluna}\")\n",
    "        axes[0].set_ylabel(\"Densidade\")\n",
    "        axes[0].axvline(df[coluna].mean(), color='red', linestyle='dashed', linewidth=2, label=\"Mean\")  # Linha da média\n",
    "        axes[0].legend() \n",
    "\n",
    "        # Boxplot\n",
    "        sns.boxplot(y=df[coluna], color=\"#F8766D\", ax=axes[1])\n",
    "        axes[1].set_title(f\"Boxplot de {coluna}\")\n",
    "\n",
    "        # Gráfico de violino\n",
    "        sns.violinplot(y=df[coluna], ax=axes[2])\n",
    "        axes[2].set_title(f\"Gráfico de Violino de {coluna}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Exemplo de uso:\n",
    "plot_histogram_boxplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>3. Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:green\">Pré-processamento e Limpeza dos dados</code>\n",
    "\n",
    "- Verificar observações sobre a análise univariada com a área de negócio e realizar tratamento dos dados\n",
    "- Criar ABT\n",
    "- Realizar transformação de dados quando necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tirando uma variavel que não será usada (contexto negocio)\n",
    "df = df.drop([\"Density\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuir o valor da média da altura de todas as observações (adultos) ao outlier de Height ( = 74.93)\n",
    "\n",
    "df['Height'] = df['Height'].replace(74.93, df['Height'].mean())\n",
    "\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>4. Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:green\">Etapas da EDA</code>\n",
    "\n",
    "- Análise bivariada\n",
    "- Avaliar e tratar multicolinearidade\n",
    "- Fazer descritiva com foco no modelo\n",
    "- Validar pressupostos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:green\">Análise Bivariada</code>\n",
    "\n",
    "- Cruzar variáveis e identificar correlação de pearson\n",
    "- Observar relação entre cada variável independente e a variável dependente para identificar correlação visualmente (vontade de traçar uma reta angular?)\n",
    "- Analisar matriz de correlação (acima de 0,7 indica alta correlação)\n",
    "- Escolher quais variáveis manter no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando gráficos de dispersão entre todas as variáveis\n",
    "\n",
    "# Ajustar o tamanho da figura\n",
    "plt.figure(figsize=(12, 10))  # Ajuste o tamanho conforme necessário\n",
    "\n",
    "# Verificar linearidade (gráficos de dispersão)\n",
    "sns.pairplot(df, corner=True)\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap para cálculo de correlação com valores de correlação\n",
    "\n",
    "# corr_matrix = pd.concat([y, X], axis=1).corr()\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Criar a máscara para a parte superior da matriz, evitando redundância já que a matriz é simétrica\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool)) \n",
    "\n",
    "# Ajustar o tamanho da figura\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Criar o heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.1f', center=0, vmax=1, vmin=-1, cmap=\"RdBu_r\", annot_kws={\"size\": 10}, mask=mask)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:purple\">Observações</code>\n",
    "\n",
    "- Pode-se observar que as variáveis Ankle, Age e Height, no gráfico de dispersão, não apresentam um comportamente linear. Vamos retirá-las do df para rodar o primeiro modelo.\n",
    "\n",
    "- Também observa-se que a variável Weight possui correlação forte com Hip, Abdomen, Chest, Thigh e Knee. Isso pode causar multicolinearidade no modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:red\">Dúvida</code>\n",
    "\n",
    "   - Ao observar que a variável Weight possui correlação forte com várias outras variáveis, como testar qual podemos retirar para gerar o melhor modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>5. Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Criando o modelo de regressão linear múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a variável dependente (y) e as independentes (X)\n",
    "\n",
    "# Criando o objeto y com a variável dependente\n",
    "y = df[\"bodyfat\"]\n",
    "# Criando a matriz X sem a variável dependente\n",
    "X = df.drop(columns=[\"bodyfat\"])  # Usando todas as variáveis independentes numéricas\n",
    "\n",
    "# Adicionando uma coluna com todos os valores = 1 para que o B0 seja calculado\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustando o modelo\n",
    "modelo_full = sm.OLS(y, X).fit()\n",
    "# Resumo do modelo\n",
    "print(modelo_full.summary())\n",
    "# Gerando a predição através deste modelo\n",
    "chute_modelo_full = modelo_full.predict(X)\n",
    "\n",
    "\"\"\"\n",
    "Existe a opção de utilizar o Scikit-Learn para predições e deploy, mas é menos detalhado para análise estatística. Não precisa adicionar constante. \n",
    "\n",
    "Para utilizar este método, separaríamos as observações em test e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:purple\">Resultados do modelo com todas as variáveis independentes</code>\n",
    "\n",
    "De acordo com os resultados obtidos na regressão utilizando todas as variáveis independentes, observa-se que:\n",
    "\n",
    "- **P>|t|**  A maior parte das variáveis independentes deste modelo são não significativas.\n",
    "- **Test F (Prob (F-statistic))**:\t9.75e-64, indica que pelo menos 1 variável independente é significativa.\n",
    "- **Cond. No.** = 4.37e+04 nos dá um indício do motivo deste resultado, já que por ser muito grande, indica alta multicolinearidade entre as variáveis.\n",
    "- **R2** = 0.749: O modelo explica 74.9% da variação do percentual de gordura corporal (bodyfat), o que indica um bom ajuste.\n",
    "- **𝑅2 ajustado** = 0.735 → Leva em conta o número de variáveis no modelo e é um pouco menor, sugerindo que algumas variáveis podem não estar contribuindo significativamente.\n",
    "**Estatística F** = 54.50 → Testa se pelo menos uma variável independente tem um coeficiente diferente de zero.\n",
    "**p-valor do F-statistic**: 9.75e-64 → Extremamente pequeno, indicando que o modelo é estatisticamente significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:purple\">Comentários</code>\n",
    "\n",
    "Antes de utilizar um método de seleção de variáveis, vamos retirar algumas variáveis do df que foram identificadas com baixa correlação com a variável dependente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma nova matriz X sem as variáveis Height, Age e Ankle\n",
    "X_manual = df.drop(columns=[\"bodyfat\", \"Height\", \"Age\", \"Ankle\"])  # Usando todas as variáveis independentes numéricas, exceto Height, Age e Ankle\n",
    "\n",
    "# Aqui lembre-se do B0. Basicamente vamos adicionar uma coluna de 1s para que o B0 seja calculado.\n",
    "X_manual = sm.add_constant(X_manual)\n",
    "# Ajustando o modelo\n",
    "manual = sm.OLS(y, X_manual).fit()\n",
    "# Resumo do modelo\n",
    "print(manual.summary()) \n",
    "# gerando a predição aravés desse modelo\n",
    "pred_manual = manual.predict(X_manual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code style=\"color:green\">Seleção de Variáveis</code>\n",
    "\n",
    "Seleção de variáveis é uma etapa que objetiva selecionar apenas as variáveis úteis para o modelo.\n",
    "\n",
    "#### <center>Métodos:\n",
    "\n",
    "1: **Lasso (Regularização L1)**: Usa uma penalização (L1) que força coeficientes irrelevantes a zero, eliminando variáveis automaticamente.\n",
    "- Melhor para: Modelos lineares, muitas variáveis\n",
    "- Vantagens: Fácil de interpretar, evita overfitting\n",
    "- Desvantagens: Pode descartar variáveis importantes\n",
    "- Popularidade: 4\n",
    "\n",
    "2: **Random Forest/XGBoost**: Calculam a importância de cada variável no modelo.\n",
    "- Melhor para: Qualquer modelo\n",
    "- Vantagens: Considera interações e relações não lineares\n",
    "- Desvantagens: Difícil de interpretar\n",
    "- Popularidade: 5\n",
    "\n",
    "3: **RFE (Seleção Recursiva)**: Remove iterativamente a variável menos importante até encontrar o melhor conjunto.\n",
    "- Melhor para: Modelos específicos (Linear, SVM)\n",
    "- Vantagens: Boa seleção para modelos pequenos\n",
    "- Desvantagens: Computacionalmente caro\n",
    "- Popularidade: 3\n",
    "\n",
    "4: **Stepwise Selection**: Testa variáveis iterativamente, adicionando (forward), removendo (backward) ou integrando o backward e forward juntos com base no p-valor ou AIC/BIC\n",
    "- Melhor para: Modelos estatísticos\n",
    "- Vantagens: Interpretável\n",
    "- Desvantagens: Propenso a overfitting, lento\n",
    "- Popularidade: 2\n",
    "\n",
    "5: **Mutual Information**: Mede a dependência entre variáveis (entropia).\n",
    "- Melhor para: Dados categóricos\n",
    "- Vantagens: Lida em com não-linearidade\n",
    "- Desvantagens: Difícil de interpretar\n",
    "- Popularidade: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Forward AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a seleção de variáveis pelo método forward com base no AIC, utilizando as funções criadas no início do documento\n",
    "\n",
    "\n",
    "# Criando o objeto X com as variáveis independentes, ou seja, tirando o que foi feito antes e a variável resposta\n",
    "\n",
    "X = df.drop([\"bodyfat\"],axis = 1)\n",
    "\n",
    "# Criando o objeto y com a variável dependente\n",
    "y = df[\"bodyfat\"]\n",
    "\n",
    "colunas_forw = step(var_dependente = 'bodyfat', var_independente = X.columns.to_list(), \n",
    "                    base = df, metodo = 'forward', metrica = 'aic')\n",
    "colunas_forw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:purple\">Observações: </code>\n",
    "\n",
    "- Note que as melhores variáveis estão na primeira linha.\n",
    "- Tanto no AIC quanto no BIC, quanto menor for o valor, melhor o modelo será\n",
    "- Agora vamos pegar essas colunas e criar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando em uma lista o nome de todas as variaveis do modelo com menor aic\n",
    "X_forw = df[colunas_forw['var'].to_list()[0]]\n",
    "# Aqui lembre-se do B0. Basicamente vamos adicionar uma coluna de 1s para que o B0 seja calculado.\n",
    "X_forw = sm.add_constant(X_forw)\n",
    "# Ajustando o modelo\n",
    "forw = sm.OLS(y, X_forw).fit()\n",
    "# Resumo do modelo\n",
    "print(forw.summary()) \n",
    "# gerando a predição aravés desse modelo\n",
    "pred_forw = forw.predict(X_forw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:purple\">Observações: </code>\n",
    "\n",
    "Por que alguns p-valores são não significativos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Backward AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressao por backward com a regra de AIC\n",
    "colunas_backw = step(var_dependente = 'bodyfat', var_independente = X.columns.to_list(), base = df, metodo = 'backward' ,metrica = 'aic')\n",
    "colunas_backw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando em uma lista o nome de todas as variaveis do modelo com menor aic\n",
    "X_backw = df[colunas_backw['var'].to_list()[0]] \n",
    "# Aqui lembre-se do B0. Basicamente vamos adicionar uma coluna de 1s para que o B0 seja calculado.\n",
    "X_backw = sm.add_constant(X_backw)\n",
    "# Ajustando o modelo\n",
    "backw = sm.OLS(y, X_backw).fit()\n",
    "# Resumo do modelo\n",
    "print(backw.summary()) \n",
    "# gerando a predição aravés desse modelo\n",
    "pred_backw = backw.predict(X_backw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Stepwise AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressao por stepwise com a regra de AIC\n",
    "colunas_stepw = step(var_dependente = 'bodyfat', var_independente = X.columns.to_list(), base = df, metodo = 'both' ,metrica = 'aic')\n",
    "colunas_stepw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando em uma lista o nome de todas as variaveis do modelo com menor aic\n",
    "X_stepw = df [ colunas_stepw['var'].to_list()[0] ] \n",
    "# Aqui lembre-se do B0. Basicamente vamos adicionar uma coluna de 1s para que o B0 seja calculado.\n",
    "X_stepw = sm.add_constant(X_stepw)\n",
    "# Ajustando o modelo\n",
    "stepw = sm.OLS(y, X_stepw).fit()\n",
    "# Resumo do modelo\n",
    "print(stepw.summary()) \n",
    "# gerando a predição aravés desse modelo\n",
    "pred_stepw = stepw.predict(X_stepw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressao por stepwise com a regra de p-valor\n",
    "\n",
    "\n",
    "colunas_stepw_p = step(var_dependente = 'bodyfat', var_independente = X.columns.to_list(), base = df, metodo = 'both' ,metrica = 'pvalor')\n",
    "colunas_stepw_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando em uma lista o nome de todas as variaveis do modelo com p-valor\n",
    "X_stepw_p = df[colunas_stepw_p['var'].to_list()] \n",
    "# Aqui lembre-se do B0. Basicamente vamos adicionar uma coluna de 1s para que o B0 seja calculado.\n",
    "X_stepw_p = sm.add_constant(X_stepw_p)\n",
    "# Ajustando o modelo\n",
    "stepw_p = sm.OLS(y, X_stepw_p).fit()\n",
    "# Resumo do modelo\n",
    "print(stepw_p.summary()) \n",
    "# gerando a predição aravés desse modelo\n",
    "pred_stepw_p = stepw_p.predict(X_stepw_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Verificando a qualidade dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code style=\"color:green\">Interpretando os Resultados - Métricas de Qualidade de Ajuste</code>\n",
    "\n",
    "- **$R^{2}$**: Mede a proporção da variação de y explicada pelo modelo. Quanto mais próximo de 1, melhor o ajuste.\n",
    "- **$R^{2}$ ajustado**: Considera o número de variáveis no modelo, penalizando modelos com variáveis explicativas irrelevantes. Se muito menor que $R^{2}$, pode indicar que algumas variáveis não contribuem significativamente. É útil para comparar modelos com diferentes quantidades de variáveis.\n",
    "- **Estatística F**: Testa a significância global do modelo, ou seja, se pelo menos uma variável independente tem um coeficiente diferente de zero. F alto, melhor. É a estatística do teste que só poderá ser interpretada se comparada a estatística F tabelada com o nível de significância de interesse.\n",
    "- **Prob (F-statistic)**: É a probabilidade da estatística F. Se (Prob (F-statistic)) < 0,05 (nível de significância), rejeita-se H0, ou seja, pelo menos uma variável independente é significativa.\n",
    "\\begin{align*}\n",
    "H_0: & \\quad \\beta_1 = \\beta_2 = \\cdots = \\beta_k = 0 \\\\\n",
    "H_1: & \\quad \\text{Ao menos um  é } \\beta_i \\neq 0\n",
    "\\end{align*}\n",
    "- **Log-Likelihood**: Mede a qualidade do ajuste (log-verossimilhança); Quanto mais positivos, melhor o modelo ajusta os dados.\n",
    "- **AIC e BIC**: Critérios para comparar modelos; valores menores indicam melhor ajuste com menos complexidade. BIC penaliza mais modelos com muitas variáveis.\n",
    "- **Coeficientes (coef)**: Representam o impacto de cada variável independente sobre y. Valores positivos indicam relação direta, e negativos indicam relação inversa. É o valor da constante no modelo de regressão. Representa o valor esperado da variável dependente quando todas as variáveis independentes são zero. Não tem interpretação.\n",
    "- **Erro padrão (std err):** Mede a incerteza na estimativa do coeficiente. Indica a precisão do coeficiente estimado. Um erro padrão menor indica uma estimativa mais precisa (ou seja, em diferentes amostras os resultados seriam os mesmos).\n",
    "- **Valor t (t)**: É o valor da estatística de teste para a significância dos coeficientes.\n",
    "- **P>|t|**: Representa o resultado do teste t para cada variável. Quando P>|t| > 0,05, não rejeitamos H0 (B=0), indicando que a variável pode não ser significativa para prever y. p>|t| < 0.05 indica que a variável tem efeito significativo no modelo.\n",
    "\\begin{align*}\n",
    "H_0: & \\quad \\beta_i = 0 \\\\\n",
    "H_1: & \\quad \\beta_i \\neq 0\n",
    "\\end{align*}\n",
    "- **Intervalo de confiança [0.025, 0.975]**: Indica a faixa na qual o coeficiente pode variar com 95% de confiança. Se o intervalo inclui 0, a variável pode não ser significativa.\n",
    "- **condition number**: Se muito grande, indica multicolinearidade.\n",
    "\n",
    "\n",
    "#### Como interpretar o modelo:\n",
    "- Se **muitas variáveis não são significativas** (P>|t| > 0,05), pode ser necessário refazer a seleção de variáveis.\n",
    "- Se **$R^{2}$ for baixo**, o modelo pode não explicar bem a variabilidade da variável dependente. Mas se for alto demais, pode indicar sobreajuste (overfitting).\n",
    "- Se **$R^{2}$ ajustado for muito menor que $R^{2}$**, o modelo pode estar incluindo variáveis irrelevantes.\n",
    "- Se **AIC/BIC forem muito altos**, pode haver um modelo mais simples com melhor desempenho.\n",
    "- Se coeficientes com p-valores baixos são mais confiáveis na previsão da variável dependente.\n",
    "- Se muitas variáveis têm p-valores altos, pode ser necessário simplificar o modelo.\n",
    "\n",
    "\n",
    "#### Calculando MAE e RMSE\n",
    "\n",
    "- **RMSE**: Valores mais próximos de 0 indicam um bom RMSE no geral, mas se o RMSE do modelo for melhor que o RMSE da média, então podemos considerar que é um bom modelo.\n",
    "- **MAE**: O MAE também mede o erro médio das previsões, mas sem elevar ao quadrado as diferenças, sendo mais interpretável e menos sensível a outliers do que o RMSE.\n",
    "Fórmula do RMSE:\n",
    "\\begin{equation} RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} \\end{equation}\n",
    "\n",
    "onde:\n",
    "\n",
    "$n$ é o número de observações.\n",
    "$y_i$ é o valor observado.\n",
    "$\\hat{y}_i$ é o valor predito.\n",
    "Fórmula do MAE:\n",
    "\\begin{equation} MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\end{equation}\n",
    "\n",
    "onde:\n",
    "\n",
    "$n$ é o número de observações.\n",
    "$y_i$ é o valor observado.\n",
    "$\\hat{y}_i$ é o valor predito.\n",
    "\n",
    "**Interpretação**:\n",
    "\n",
    "MAE mede o erro médio absoluto das previsões, penalizando todas as diferenças de forma linear.\n",
    "RMSE penaliza erros maiores de forma quadrática, sendo mais sensível a outliers.\n",
    "Comparação: Se MAE e RMSE são próximos, os erros estão distribuídos de maneira uniforme. Se RMSE for muito maior que o MAE, significa que há alguns erros muito grandes (outliers influentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame para armazenar os resultados de cada modelo (AIC, BIC, RMSE, MAE e R²)\n",
    "\n",
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['Modelo Completo', 'Modelo Manual', 'Forward Stepwise', 'Backward Stepwise', 'Stepwise AIC', 'Stepwise P-Valor'],\n",
    "    'AIC': [modelo_full.aic, manual.aic, forw.aic, backw.aic, stepw.aic, stepw_p.aic],\n",
    "    'BIC': [modelo_full.bic, manual.bic, forw.bic, backw.bic, stepw.bic, stepw_p.bic],\n",
    "    'RMSE': [np.sqrt(mean_squared_error(y, chute_modelo_full)), \n",
    "             np.sqrt(mean_squared_error(y, pred_manual)), \n",
    "             np.sqrt(mean_squared_error(y, pred_forw)), \n",
    "             np.sqrt(mean_squared_error(y, pred_backw)), \n",
    "             np.sqrt(mean_squared_error(y, pred_stepw)), \n",
    "             np.sqrt(mean_squared_error(y, pred_stepw_p))],\n",
    "    'R²': [r2_score(y, chute_modelo_full), \n",
    "           r2_score(y, pred_manual), \n",
    "           r2_score(y, pred_forw), \n",
    "           r2_score(y, pred_backw), \n",
    "           r2_score(y, pred_stepw), \n",
    "           r2_score(y, pred_stepw_p)],\n",
    "    'MAE': [mean_absolute_error(y, chute_modelo_full), \n",
    "            mean_absolute_error(y, pred_manual), \n",
    "            mean_absolute_error(y, pred_forw), \n",
    "            mean_absolute_error(y, pred_backw), \n",
    "            mean_absolute_error(y, pred_stepw), \n",
    "            mean_absolute_error(y, pred_stepw_p)]\n",
    "})\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "# Exibir os resultados formatados como tabela\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code style=\"color:green\">Comparando modelos</code>\n",
    "\n",
    "- **AIC, BIC, RMSE E MAE**: Quanto menor, melhor\n",
    "- **${R^2}$**: Quanto maior, melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como os modelos ficaram os mesmos (backward pelo AIC, forward pelo AIC e setpwise pelo AIC)\n",
    "tentativas = pd.DataFrame({\n",
    "'chute_modelo_full': chute_modelo_full,\n",
    "'chute_modelo_step_aic': pred_stepw,\n",
    "'chute_modelo_step_pvalor':pred_stepw_p,\n",
    "'chute_modelo_manual': pred_manual,\n",
    "})\n",
    "tentativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o tamanho da área do gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "# adicionando a primeira camada que são nossos dados reais em azul\n",
    "plt.scatter(df[\"bodyfat\"], df[\"bodyfat\"], color='blue', label='real')\n",
    "# adicionando a camada do chute da média em vermelho\n",
    "df[\"chute_media\"] = df[\"bodyfat\"].mean()\n",
    "plt.scatter(df[\"chute_media\"], df[\"bodyfat\"], color='red', label='chute_media')\n",
    "# adicionando a camada das nossas predições do modelo completo (sem nenhuma seleção) em verde\n",
    "plt.scatter(tentativas[\"chute_modelo_full\"], df[\"bodyfat\"], color='green', label='chute_modelo_full')\n",
    "# adicionando a camada das nossas predições do modelo stepwise pelo aic em laranja\n",
    "plt.scatter(tentativas[\"chute_modelo_step_aic\"], df[\"bodyfat\"], color='orange', label='chute_modelo_step_aic')\n",
    "# adicionando a camada das nossas predições do modelo stepwise por p-valor em pink\n",
    "plt.scatter(tentativas[\"chute_modelo_step_pvalor\"], df[\"bodyfat\"], color='pink', label='chute_modelo_step_pvalor')\n",
    "# adicionando a camada das nossas predições do modelo manual em roxo\n",
    "plt.scatter(tentativas[\"chute_modelo_manual\"], df[\"bodyfat\"], color='purple', label='chute_modelo_manual')\n",
    "\n",
    "plt.xlabel('Nosso Desenho')\n",
    "plt.ylabel('Arte Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:purple\">Comentários:</code>\n",
    "\n",
    "Vamos seguir com a análise do modelo stepw_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:green\">Comparar efeitos e variações</code>\n",
    "\n",
    "- Analisar os nossos coeficientes observando o intervalo de confiança (apesar que já sai no summary)\n",
    "- Vamos gerar os gráficos dos intervalos para facilitar a visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando o intervalo de confiança dos coeficientes menos o B0\n",
    "intervalo_confianca_forward = stepw_p.conf_int(alpha=0.05)[1:] \n",
    "intervalo_confianca_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando o gráfico para o intervalo de confiança\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "ax.errorbar(stepw_p.params.drop(['const']), # pegando os valores dos coeficientes e retirando a constante \n",
    "            stepw_p.params.drop(['const']).index,  # pegando os nomes dos coeficientes e retirando a constante\n",
    "            xerr=[stepw_p.params.drop(['const']) - intervalo_confianca_forward[0], # criando as barras dos intervalos (limite inferior) \n",
    "                  intervalo_confianca_forward[1] - stepw_p.params.drop(['const'])], # criando as barras dos intervalos (limite superior)\n",
    "            fmt='o', capsize=5)\n",
    "\n",
    "ax.set_xlabel('Coeficientes') # adicionando o rótulo do eixo x\n",
    "ax.set_ylabel('Variáveis') # adicionando o rótulo do eixo y\n",
    "ax.axvline(x=0,linestyle='--', color = \"#440154FF\") # criando uma linha vertical no x = 0\n",
    "plt.xticks(rotation=45) # adicionando uma rotação de 45 graus nos valores de x\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"color:purple\">Comentários:</code>\n",
    "\n",
    "- Quando algum intervalo corta a linha do 0 significa que o coeficiente não foi significativo.\n",
    "- Note que todas, neste caso, foram significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Validando o modelo\n",
    "\n",
    "#### <code style=\"color:green\">Análise de resíduos</code>\n",
    "\n",
    "O resíduo nada mais é que o erro do nosso modelo, ou seja o quanto ele está errando ao tentar prever a variável dependente. Nesse caso, devemos analisar um conjunto de características para considerar o nosso modelo como um modelo robusto:\n",
    " \n",
    "- Homogeneidade de variâncias: Vamos analisar o gráfico das predições sobre os resíduos. Se tiver algum tipo de padrão então as variâncias dos nossos resíduos são heterocedásticas, isto é, não homogêneas.\n",
    "\n",
    "- Normalidade: Os resíduos precisam seguir uma distribuição normal com média igual a 0. Para isso vamos usar o QQ-Plot e teste estatístico\n",
    "\n",
    "- Independência: Os resíduos não podem apresentar nenhum padrão conforme a variação de ychapeu\n",
    "\n",
    "#### <code style=\"color:green\">Qualidade dos Resíduos</code>\n",
    "\n",
    "- **Omnibus**: O teste Omnibus avalia se os resíduos seguem uma distribuição normal, considerando a assimetria e a curtose dos resíduos. Um valor de p grande sugere que os resíduos podem ser normais. Este valor representa a estatística do teste.\n",
    "\n",
    "- **Prob(Omnibus)**: Valor-p associado ao teste Omnibus, indicando a probabilidade de observar o resultado dado se a hipótese nula de distribuição normal for verdadeira. Idealmente, esperamos que os resíduos sejam normais para garantir que os pressupostos do modelo estejam corretos.\n",
    "\n",
    "\\begin{align*}\n",
    "H_{0}: & \\quad \\text{Os resíduos são normais} \\\\\n",
    "H_{1}: & \\quad \\text{Os resíduos não são normais}\n",
    "\\end{align*}\n",
    "\n",
    "- **Skew**: Mede a assimetria da distribuição dos dados. Valores negativos de Skew indicam uma cauda mais longa à esquerda (distribuição assimétrica negativa), enquanto valores positivos indicam uma cauda mais longa à direita (distribuição assimétrica positiva).\n",
    "\n",
    "- **Kurtosis**: Mede se a distribuição dos dados tem caudas mais pesadas ou mais leves em relação à distribuição normal. Valores de curtose maiores que 3 indicam que os dados têm caudas mais pesadas ou uma distribuição mais pontuda do que a normal.\n",
    "\n",
    "- **Durbin-Watson**: Testa a autocorrelação nos resíduos de uma análise de regressão. O ideal é que os resíduos não sejam correlacionados entre si. Valores de Durbin-Watson próximos de 2 sugerem que não há autocorrelação nos resíduos. Valores próximos de 0 indicam autocorrelação positiva (os resíduos consecutivos estão correlacionados), enquanto valores próximos de 4 indicam autocorrelação negativa.\n",
    "\n",
    "\\begin{align*}\n",
    "H_0: & \\quad \\text{Não há autocorrelação nos resíduos} \\\\\n",
    "H_1: & \\quad \\text{Há autocorrelação nos resíduos}\n",
    "\\end{align*}\n",
    "\n",
    "- **Jarque-Bera (JB)**: O teste de Jarque-Bera verifica se os resíduos têm assimetria e curtose compatíveis com uma distribuição normal, baseando-se em uma combinação dessas duas métricas.\n",
    "\n",
    "- **Prob(JB)**: Valor-p para o teste Jarque-Bera, avaliando a probabilidade de observar tais estatísticas se a assimetria e a curtose corresponderem a uma distribuição normal.\n",
    "\n",
    "\\begin{align*}\n",
    "H_0: & \\quad \\text{Os dados possuem assimetria e curtose que correspondem a uma distribuição normal} \\\\\n",
    "H_1: & \\quad \\text{Os dados não possuem assimetria e curtose que correspondem a uma distribuição normal}\n",
    "\\end{align*}\n",
    "\n",
    "- **Cond. No**: O Número de Condição avalia a multicolinearidade, ou seja, a correlação entre as variáveis independentes. Valores muito altos (geralmente acima de 30) indicam forte multicolinearidade, o que pode comprometer a estabilidade dos coeficientes estimados no modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando gráfico de resíduos (resíduo x predito)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(tentativas[\"chute_modelo_step_pvalor\"],stepw_p.resid, color='black')\n",
    "plt.axhline(y=0, color = 'black')\n",
    "plt.xlabel('Valores Ajustados')\n",
    "plt.ylabel('Resíduos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:purple\">Observações:</code>\n",
    "\n",
    "- Note que os resíduos não apresentam nenhum padrão, ou seja, demonstram independência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:green\">Teste de Normalidade de Shapiro + QQ-plot + Histograma</code>\n",
    "\n",
    "Gráficos são um pouco subjetivos. Dependendo do problema não dá para enxergar algo ou tirar uma conclusão. \n",
    "Testes estatísticos são mais confiáveis, portanto é melhor testar a normalidade e a homogeneidade de variâncias.\n",
    "\n",
    "Normalidade (Shapiro-Wilk):\n",
    "\n",
    "- $H_{0}:$ Os resíduos são normais\n",
    "- $H_{1}:$ Os resíduos não são normais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ele gera a estatística do teste e o p-valor\n",
    "shapiro(stepw_p.resid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qqplot \n",
    "stats.probplot(stepw_p.resid, dist=\"norm\",plot=pylab)\n",
    "pylab.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando o histograma\n",
    "stepw_p.resid.plot(kind='hist', bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:purple\">Observações:</code>\n",
    "\n",
    "- Note que não rejeitamos $H_{0}$, logo os resíduos podem ser considerados como normais.\n",
    "- Para que sejam considerados normais, os resíduos precisam seguir a linha em vermelho no qq-plot, o que pode indicar, novamente, normalidade.\n",
    "- Pelo histograma, vemos um gráfico bem próximo da normalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:green\">Teste de Homogeneidade de Variância</code>\n",
    "\n",
    "Validando o pressuposto de Homogeneidade de Variâncias através do teste de Breusch-Pagan:\n",
    "\n",
    "- $H_{0}:$ Os resíduos possuem homogeneidade nas variâncias\n",
    "- $H_{1}:$ Os resíduos não possuem homogeneidade nas variâncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o teste de Breusch-Pagan para verificar heterocedasticidade\n",
    "# Passamos os resíduos do modelo (stepw_p.resid) e as variáveis explicativas (stepw_p.model.exog)\n",
    "teste_bp = het_breuschpagan(stepw_p.resid, stepw_p.model.exog)\n",
    "# Definindo os rótulos para os resultados do teste\n",
    "rotulos = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\n",
    "# Usando zip para associar cada rótulo ao seu respectivo resultado do teste e convertendo em um dicionário\n",
    "resultado_bp = dict(zip(rotulos, teste_bp))\n",
    "# Exibindo o p-valor do LM-Test\n",
    "print(resultado_bp['LM-Test p-value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:purple\">Observações:</code>\n",
    "\n",
    "- Não rejeitamos $H_{0}$, logo as variâncias dos resíduos podem ser consideradas homogêneas.\n",
    "- Sendo assim, esse modelo passou nos 4 pressupostos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:green\">Multicolinearidade</code>\n",
    "\n",
    "A multicolinearidade é um problema quando estamos tentando criar nosso modelo. Ela ocorre quando temos um conjunto de variáveis INDEPENDENTES que são altamente correlacionadas umas com as outras, o que gera um modelo com pouca confiabilidade. \n",
    "\n",
    "Vou analisar direto o VIF do modelo stepw_p:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um dataframe vazio\n",
    "vif = pd.DataFrame() \n",
    "# adicionando as colunas que você quer analisar (deixe a coluna const!)\n",
    "vif[\"Variáveis\"] =X_stepw_p.columns \n",
    "# para cada coluna, calcule o VIF\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_stepw_p.values, i) for i in range(len(X_stepw_p.columns))] \n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code style=\"color:purple\">Observações:</code>\n",
    "\n",
    "- Normalmente, utiliza-se VIF entre 3 ou 5, ou seja, este modelo, por mais que tenha passado na análise de resíduo está com o dilema da multicolinearidade.\n",
    "\n",
    "- Uma variável pode influenciar no VIF da outra, por isso sempre começar observando a matriz de correlação a fim de selecionar as variáveis que fazem mais sentido serem mantidas. Diminuindo assim a chance de ter VIF alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos pegar da primeira até  a 14 coluna\n",
    "correlacao = df[df.columns[np.arange(0,13)]].corr(method='pearson')\n",
    "\n",
    "# Visualiza a matriz de correlação\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlacao, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "# Heatmap para cálculo de correlação\n",
    "\n",
    "# corr_matrix = pd.concat([y, X], axis=1).corr()\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Criar a máscara para a parte superior da matriz, evitando redundância já que a matriz é simétrica\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool)) \n",
    "\n",
    "# Ajustar o tamanho da figura\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Criar o heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', center=0, vmax=1, vmin=-1, cmap=\"RdBu_r\", annot_kws={\"size\": 10}, mask=mask)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
